# LearningRuleSimilarities

This repository implements models to approximate animal learning rules using DNNs or RNNs on the IBL dataset. It follows the setup and data used in [1], along with the code environment from https://github.com/pillowlab/psytrack_learning. 


## Usage 

Step 1 - Setup:
   Run the command `python3 setup.py`.
   Refer to the comments in setup.py for troubleshooting if any issues occur.

Step 2 - Train a Model:
   Execute `python3 multisys_pipeline/main_train_model.py`.
   You can modify the command line arguments to specify hyperparameters and select the learning rule (e.g., `learning_mode=0` for BPTT and `learning_mode=1` for e-prop).

   Example: 
   `python3 multisys_pipeline/main_train_model.py --learning_mode=0 --random_seed=1`
   `python3 multisys_pipeline/main_train_model.py --learning_mode=0 --random_seed=2`
   `python3 multisys_pipeline/main_train_model.py --learning_mode=1 --random_seed=1`
   `python3 multisys_pipeline/main_train_model.py --learning_mode=1 --random_seed=2`

Step 3 - Run Analysis:
   Execute `python3 multisys_pipeline/main_analyze_models.py`.
   Modify the block of code below line 72 to specify which models to include in the analysis.


Please be advised that the included code supports the training and analysis pipeline for the publicly available Mante 2013 dataset (accessible at https://www.ini.uzh.ch/en/research/groups/mante/data.html) and Hatsopoulos2007 dataset (https://datadryad.org/dataset/doi:10.5061/dryad.xsj3tx9cm). The Sussillo 2015 data is not included as we do not have permission to redistribute it. The reader may contact Mark Churchland for access to that dataset. The pipeline utilizes preprocessed neural data, where spikes are converted to rate data and each trial represents a condition average. For RNN training, synthetic data generated by Neurogym is used, with the shape n_conditions by n_steps by n_neurons. 

## Reference 

[1] Liu Y.H., Yang R.G., Cueva C.J., “Can Biologically Plausible Temporal Credit Assignment Rules Match BPTT for Neural Similarity? E-prop as an Example”, International Conference on Machine Learning (ICML), 2025 (accepted). 
